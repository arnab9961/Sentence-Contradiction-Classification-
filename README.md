# ğŸ“Œ Sentence Contradiction Classification

## **Introduction**  
The goal of this project is to classify pairs of sentences as **"contradiction," "entailment," or "neutral"** based on their meaning. The task requires building a model that can understand semantic relationships between text pairs.

---

## **ğŸ“‚ 1. Reading the Dataset**  
The dataset contains **multiple sentence pairs** with labels indicating their relationship.  

âœ… **Filtered the dataset to include only English sentences.**  
âœ… **Removed missing and duplicate values.**  

---

## **ğŸ“Š 2. Exploratory Data Analysis (EDA)**  
Before training the model, we analyzed the data:  
âœ… **Checked label distribution to see how many contradiction, entailment, and neutral cases exist.**  
âœ… **Visualized word distributions using graphs.**  
âœ… **Generated statistical summaries of numerical features.**  

---

## **ğŸ” 3. Text Preprocessing Pipeline**  
âœ… **Removing HTML tags**  
âœ… **Removing Punctuations**  
âœ… **Performing Lemmatization**  
âœ… **Performing Lowercase**  
âœ… **Removing Stopwords**  
âœ… **Decontracting words**  
âœ… **Replacing special characters with their string symbols**  

---

## **âš™ï¸ 4. Feature Engineering**  
âœ… **Added key sentence-level features:**  
  - `sentence1_len`, `sentence2_len`, `common_word_count`, `word_overlap_ratio`  
âœ… **Applied TF-IDF (Term Frequency-Inverse Document Frequency) vectorization.**  
âœ… **Extracted word embeddings to enhance semantic understanding.**  

---

## **ğŸ¤– 5. Model Building & Training**  

The dataset was split into:  
âœ… **80% Training Data**  
âœ… **20% Test Data**  

We tested multiple machine learning models:  
âœ… **Logistic Regression**  
âœ… **Random Forest**  
âœ… **XGBoost (XGB)**  
âœ… **Support Vector Machine (SVM)**  
âœ… **Artificial Neural Network (ANN) using Keras**  
âœ… **LSTM for sequence-based learning**  
âœ… **BERT for advanced NLP understanding**  

We also performed **Grid Search** for **hyperparameter tuning**.  

---

## **ğŸ“ˆ 6. Model Evaluation**  

| **Model**              | **Accuracy** | **F1-Score** |
|------------------------|-------------|--------------|
| Logistic Regression   | **45.05%**   | **44.92%**   |
| Random Forest        | **44.25%**   | **43.55%**   |
| XGB                  | **45.12%**   | **44.82%**   |
| ANN                  | **39.37%**   | **31.55%**   |
| Decision Tree        | **39.96%**   | **39.96%**   |

âœ… **XGB performed the best**, achieving **45.12% accuracy**.  
âœ… A **confusion matrix** was used to analyze model errors.  

---

## **ğŸš€ 7. Deployment**  
We deployed the model using **Streamlit**, allowing users to:  
âœ… Enter **two sentences**  
âœ… Get a **classification result (Contradiction, Entailment, or Neutral)**  

ğŸ”— **Try the Web App:** [ğŸ‘‰ Click Here](https://sentenceclassifier.streamlit.app/)  

![Application Screenshot](image.png)
